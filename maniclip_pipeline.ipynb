{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMlcm4V8wCPSGjEln3eMDsL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavaris-pm/ManiCLIP/blob/for-colab/maniclip_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `ManiCLIP`: Multi-Attribute Face Editing\n",
        "- dedicated training and architecture setup by Mr. Pavaris Ruangchutiphophan (`github`: pavaris-pm)\n",
        "\n",
        "-------------------------------------------\n",
        "\n",
        "\n",
        "## FAQs\n",
        "- always read it before asking up any question, if it is already in here, i will not answer it even you contact me about it\n",
        "\n",
        "### Q1.) Did this notebook is an implementation of ManiCLIP ?\n",
        "\n",
        "`Ans`: Yes, however, i'm mainly coding in GitHub codespace so that whatever changes i've made will be pushed directly to the repository and will use Google colab to execute the script instead. It is waste of my time to implement it on both environment. Therefore, if you have any question, just lookup the code in the repo, i already leave a comment on it already.\n",
        "\n",
        "---------------------------------------\n",
        "\n",
        "\n",
        "### Q2.) I couldn't run it on my environment, how could i do it ?\n",
        "\n",
        "`Ans`: if you're working on codespace e.g. github codespace, vscode etc.. I recommend you to create a new environment via `env` command by create it from `environment.yaml` file that on this repo. Since the version of `torchvision` library is somewhat needed a specific version (many GANs implementation mainly rely on `vutils` function), for colab, please make sure that you've clone the correct repo (branch name: `for-colab`)\n",
        "\n",
        "\n",
        "\n",
        "```cli\n",
        "!git clone --branch for-colab https://github.com/pavaris-pm/ManiCLIP.git\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "\n",
        "  ### Q3.) What is an expected result of this implementation ?\n",
        "\n",
        "  `Ans`: this is one of the new way of face editing task since many models always handle with only single-attribute only (except with conditional gan that seems much on give a condition, however, its training scheme always look heavy if we training it on the attributes/latent as always) with that ManiCLIP coming out to handle multi-face attribute with a very new training scheme (like think outside-the-box manner)\n",
        "\n",
        "\n",
        "  Apart from that, i projected to improve it in order to handle with low-resource language so that it will be accessed by most of people to build their own generation models from now on since i saw a possible implementation to get this done, and now i', currently working on it (it'll be done if i'm not that lazy ğŸ˜­).\n",
        "\n",
        "\n",
        "  -----------------------------------------\n",
        "  \n",
        "   ### Q4.) since you pull some data from Google drive, will the resource on the google drive published?\n",
        "   ```python\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "   ```\n",
        "\n",
        "  `Ans`: No. I will not share all of my resources used to train the model. Everything buildup in this repo can be followed based on the `readme.md` file. Just follow it can replicate the paper as well.\n",
        "\n",
        "  -----------------------------------------\n",
        "\n",
        "  ### Q5.) What if i have a question about this model ?\n",
        "\n",
        "  `Ans`: i'm a very active developer on github, any questions coming up from this implementation. It is better to open up an issue on my repo and do not forget to `@pavaris-pm` for notify me to read it, i will answer it immediately.\n",
        "\n",
        "  -----------------------------------------"
      ],
      "metadata": {
        "id": "Lwq2IknEjzWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "8-xAj42-fgs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OzX9CcKSfiGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f74f791-5d58-4104-883e-57ce66966560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcGa3QlyaUvk",
        "outputId": "6fa97d7f-47db-4dfc-feeb-2d552884c3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ManiCLIP'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 53 (delta 9), reused 0 (delta 0), pack-reused 35\u001b[K\n",
            "Receiving objects: 100% (53/53), 57.95 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch for-colab https://github.com/pavaris-pm/ManiCLIP.git\n",
        "# to obtain dataset, it will decompressed into ./\n",
        "#!unzip -q /content/drive/MyDrive/SpatialAttGAN/CelebA/Img/img_align_celeba.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install open_clip_torch\n",
        "!pip -q install clip\n",
        "!pip -q install ninja\n",
        "!pip -q install git+https://github.com/openai/CLIP.git\n",
        "!pip -q install multilingual-clip torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MlxLNNPbHtr",
        "outputId": "3d33c3ed-9e6f-4e10-d6bd-882d1a9d3e02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# directory setup\n",
        "import os\n",
        "folder_path = \"/content/pretrained/\"  # Replace with the actual path you want\n",
        "data_path = \"/content/data/\"\n",
        "# Use os.makedirs with exist_ok=True to create the folder only if it doesn't exist\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "os.makedirs(data_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "ex83ovrLp_C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to format the directory structure\n",
        "!cp /content/drive/MyDrive/SpatialAttGAN/OneDrive_1_09-12-2023/* /content/pretrained/\n",
        "!cp /content/ManiCLIP/data/* /content/data/\n",
        "!cp /content/drive/MyDrive/SpatialAttGAN/CelebA/Anno/list_attr_celeba.txt /content/data/"
      ],
      "metadata": {
        "id": "IHnCWgsyqIxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pciAkRnC-R_",
        "outputId": "387ce79e-c60a-43d1-c068-9c4df210e8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "- Note that ManiCLIP offered a new traning scheme that is very much impressive, better to take a look at the paper\n",
        "- requirements for run the script must be created"
      ],
      "metadata": {
        "id": "IpMyofZGbA86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# script argument lookup (can be customed on your own)\n",
        "!python /content/ManiCLIP/train.py --help"
      ],
      "metadata": {
        "id": "1XYEExPjjTx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python /content/ManiCLIP/train.py --epochs 1 --loss_id_weight 0.05 --loss_w_norm_weight 0.1 --loss_clip_weight 1.0 --loss_face_norm_weight 0.05 --loss_minmaxentropy_weight 0.2 --loss_face_bg_weight 1 --task_name name --decouple --part_sample_num 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUXxVVueazU3",
        "outputId": "f13bbbe1-f7d7-4581-bd10-201a210478e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 13:18:48.696794: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 13:18:48.696852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 13:18:48.696897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 13:18:49.848968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/ManiCLIP/train.py:127: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.\n",
            "  warnings.warn('You have chosen to seed training. '\n",
            "Use GPU: 0 for training\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338M/338M [00:02<00:00, 158MiB/s]\n",
            "Loading ResNet ArcFace for ID Loss\n",
            "TransModel(\n",
            "  (clip_model): CLIP(\n",
            "    (visual): VisionTransformer(\n",
            "      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
            "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (transformer): Transformer(\n",
            "        (resblocks): Sequential(\n",
            "          (0): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (6): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (7): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (8): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (9): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (10): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (11): ResidualAttentionBlock(\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): QuickGELU()\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (resblocks): Sequential(\n",
            "        (0): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): ResidualAttentionBlock(\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): QuickGELU()\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (token_embedding): Embedding(49408, 512)\n",
            "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (face_pool): AdaptiveAvgPool2d(output_size=(224, 224))\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (x_map): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (text_map): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (decoder): TransformerDecoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.2, inplace=False)\n",
            "        (dropout2): Dropout(p=0.2, inplace=False)\n",
            "        (dropout3): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ManiCLIP/train.py\", line 749, in <module>\n",
            "    main()\n",
            "  File \"/content/ManiCLIP/train.py\", line 133, in main\n",
            "    main_worker(args.gpu, args)\n",
            "  File \"/content/ManiCLIP/train.py\", line 186, in main_worker\n",
            "    dataset_train = PartTextDataset(split='train', sample_num=args.part_sample_num)\n",
            "  File \"/content/ManiCLIP/train.py\", line 620, in __init__\n",
            "    f = open('data/list_attr_celeba.txt')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/list_attr_celeba.txt'\n",
            "CPU times: user 878 ms, sys: 131 ms, total: 1.01 s\n",
            "Wall time: 2min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "OPxmiykruwut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ManiCLIP/generate.py \\\n",
        "--model_path pretrained/pretrained_edit_model.pth.tar \\\n",
        "--text \"this person has grey hair. he has red lips, and black mustache.\" \\\n",
        "--gen_num 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc-dLza-q_OV",
        "outputId": "40f185a8-2cbb-4b47-c16e-68fee14f949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 14:12:13.948777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 14:12:13.948840: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 14:12:13.948879: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 14:12:15.627390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/ManiCLIP/external/stylegan2/op/conv2d_gradfix.py:88: UserWarning: conv2d_gradfix not supported on PyTorch 2.1.0+cu118. Falling back to torch.nn.functional.conv2d().\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Future Work`: Low-Resource ManiCLIP ğŸš§"
      ],
      "metadata": {
        "id": "HblmCFHmfBWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment of ManiCLIP on Thai Language\n",
        "!python /content/ManiCLIP/generate.py \\\n",
        "--model_path pretrained/pretrained_edit_model.pth.tar \\\n",
        "--text 'à¸„à¸™à¸™à¸µà¹‰à¸œà¸¡à¸«à¸‡à¸­à¸ à¸›à¸²à¸à¹à¸”à¸‡ à¸¡à¸µà¸«à¸™à¸§à¸”à¸”à¸³' \\\n",
        "--gen_num 1"
      ],
      "metadata": {
        "id": "tpab59UC726a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment of ManiCLIP on Japanese Language\n",
        "!python /content/ManiCLIP/generate.py \\\n",
        "--model_path pretrained/pretrained_edit_model.pth.tar \\\n",
        "--text 'ã“ã®äººã¯ç™½é«ªã€èµ¤ã„å”‡ã€é»’ã„å£ã²ã’ã‚’æŒã£ã¦ã„ã¾ã™ã€‚' \\\n",
        "--gen_num 1"
      ],
      "metadata": {
        "id": "cM9T9PLLkamW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment of ManiCLIP on Korean Language\n",
        "!python /content/ManiCLIP/generate.py \\\n",
        "--model_path pretrained/pretrained_edit_model.pth.tar \\\n",
        "--text 'ì´ ì‚¬ëŒì€ íšŒìƒ‰ ë¨¸ë¦¬ì— ë¶‰ì€ ì…ìˆ , ê²€ì€ ì½§ìˆ˜ì—¼ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.' \\\n",
        "--gen_num 1"
      ],
      "metadata": {
        "id": "y040p5kDkf3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}